## ğŸŒ€ ë¬¸ì œ 1 SIFTë¥¼ ì´ìš©í•œ íŠ¹ì§•ì  ê²€ì¶œ ë° ì‹œê°í™”

> ì´ë¯¸ì§€ë¥¼ ì´ìš©í•˜ì—¬ **SIFT(Scale-Invariant Feature Transform) ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ íŠ¹ì§•ì ì„ ê²€ì¶œ**í•˜ê³  ì‹œê°í™”
---
**SIFT** <br><br>
![image](https://github.com/user-attachments/assets/9d856265-b7b2-4aa9-860c-2c1d87a9488c)

### ğŸ“„ ì½”ë“œ 
- SIFT.py

*ì „ì²´ ì½”ë“œ*
```python
import cv2 as cv
import matplotlib.pyplot as plt

img = cv.imread('mot_color70.jpg')
img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)

gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)

sift = cv.SIFT_create(nfeatures=0)  

kp, des = sift.detectAndCompute(gray, None)

img_kp = cv.drawKeypoints(img_rgb, kp, None, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.imshow(img_rgb)
plt.title('Original')
plt.axis('off')

plt.subplot(1, 2, 2)
plt.imshow(img_kp)
plt.title('SIFT result')
plt.axis('off')

plt.tight_layout()
plt.show()
```
*í•µì‹¬ì½”ë“œ* <br>
**ğŸ”· grayscale ì´ë¯¸ì§€ ë³€í™˜**
```python
gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
```
ğŸ”¹ BGR ì´ë¯¸ì§€ë¥¼ Grayscale ì´ë¯¸ì§€ë¡œ ë³€í™˜
<br><br>
**ğŸ”· Sobel edge ê²€ì¶œ**
```python
grad_x = cv.Sobel(gray, cv.CV_32F, 1, 0, ksize=3)
grad_y = cv.Sobel(gray, cv.CV_32F, 0, 1, ksize=3)
```
ğŸ”¹ cv.Sobel() í•¨ìˆ˜ë¡œ ìˆ˜í‰(x), ìˆ˜ì§(y) ë°©í–¥ì˜ ë¯¸í™˜
<br><br>

### :octocat: ì‹¤í–‰ ê²°ê³¼

![Figure 2025-04-01 152956](https://github.com/user-attachments/assets/a77544fc-b252-4442-af9c-71e016998634)
<br><br>
## ğŸŒ€ ë¬¸ì œ 2 SIFTë¥¼ ì´ìš©í•œ ë‘ ì˜ìƒ ê°„ íŠ¹ì§•ì  ë§¤ì¹­ì¹­

> Canny ì—ì§€ ê²€ì¶œì„ ì‚¬ìš©í•˜ì—¬ ì—ì§€ ë§µ ìƒì„± í›„ **í—ˆí”„ ë³€í™˜ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ ì§ì„  ê²€ì¶œ**
---

### Hough Transform (í—ˆí”„ ë³€í™˜)
![image](https://github.com/user-attachments/assets/acbb191e-a6f7-450b-b035-318c6cd15582)

### ğŸ“„ ì½”ë“œ 
- Hough.py

*ì „ì²´ ì½”ë“œ*
```python
import cv2 as cv
import numpy as np
import time
import matplotlib.pyplot as plt

img1 = cv.imread('mot_color70.jpg')
img1 = img1[190:350, 440:560]  

img2 = cv.imread('mot_color83.jpg')

gray1 = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)
gray2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)

sift = cv.SIFT_create()
kp1, des1 = sift.detectAndCompute(gray1, None)
kp2, des2 = sift.detectAndCompute(gray2, None)
print('Feature :', len(kp1), len(kp2))

start = time.time()
flann = cv.DescriptorMatcher_create(cv.DescriptorMatcher_FLANNBASED)
knn_match = flann.knnMatch(des1, des2, 2)

T = 0.7
good_match = []
for nearest1, nearest2 in knn_match:
    if (nearest1.distance / nearest2.distance) < T:
        good_match.append(nearest1)
print('Time :', time.time() - start)

img_match = cv.drawMatches(img1, kp1, img2, kp2, good_match, None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

img_match_rgb = cv.cvtColor(img_match, cv.COLOR_BGR2RGB)

plt.figure(figsize=(12, 6))
plt.imshow(img_match_rgb)
plt.title('FLANN result')
plt.axis('off')
plt.show()
```

*í•µì‹¬ ì½”ë“œ* <br>
**ğŸ”· Grayscale ë³€í™˜ í›„ Canny edge detection**
```python
gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
edges = cv.Canny(gray, 100, 200)
```
ğŸ”¹ edge ê²€ì¶œì„ ìœ„í•´ ì´ë¯¸ì§€ Grayscale ë³€í™˜ <br>
ğŸ”¹ cv.Canny() í•¨ìˆ˜ë¡œ edge map ìƒì„±
<br><br>
**ğŸ”· Hough Transformì„ ì´ìš©í•´ ì§ì„  ê²€ì¶œ**
```python
lines = cv.HoughLinesP(edges, rho=1, theta=np.pi/180, threshold=90, minLineLength=40, maxLineGap=5)
```
ğŸ”¹ cv.HoughLinesP()ì„ ì´ìš©í•´ ì§ì„  ê²€ì¶œ <br>
ğŸ”¹ rho=1 : ê±°ë¦¬ resolution (pixel ë‹¨ìœ„) <br>
ğŸ”¹ theta=np.pi/180 : ê°ë„ resolution (1ë„) <br>
ğŸ”¹ threshold=90 : ì„ê³—ê°’ <br>
ğŸ”¹ minLineLength=40 : ìµœì†Œ ì§ì„  ê¸¸ì´ <br>
ğŸ”¹ maxLineGap=5 : ì„ ë¶„ ê°„ ìµœëŒ€ í—ˆìš© ê±°ë¦¬ (ì—°ê²° ì¡°ê±´)
<br><br>
**ğŸ”· Hough Transform ì‹œê°í™”**
```python
img_lines = img.copy()
if lines is not None:
    for line in lines:
        x1, y1, x2, y2 = line[0]
        cv.line(img_lines, (x1, y1), (x2, y2), (0, 0, 255), 2))
```
ğŸ”¹ ì›ë³¸ ì´ë¯¸ì§€ì— ì„ ì„ ì§ì ‘ ê·¸ë¦¬ì§€ ì•Šê¸° ìœ„í•´ ë³µì‚¬ë³¸ ìƒì„± <br>
ğŸ”¹ ê²€ì¶œëœ ëª¨ë“  ì§ì„ ì„ ë¹¨ê°„ìƒ‰ ì§ì„ ìœ¼ë¡œ ì‹œê°í™”  <br>
<br><br>
**ğŸ”· matplotlib ì‚¬ìš©ì„ ìœ„í•œ RGB image ë³€í™˜**
```python
img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)
img_lines_rgb = cv.cvtColor(img_lines, cv.COLOR_BGR2RGB)
```
ğŸ”¹ OpenCVëŠ” BGR imageì´ê³  matplotlibëŠ” RGB imageì´ê¸° ë•Œë¬¸ì— ë³€í™˜ <br>
<br><br>
### :octocat: ì‹¤í–‰ ê²°ê³¼

![Figure 2025-04-01 165852](https://github.com/user-attachments/assets/31428164-9548-42ba-be5f-338a7b7044e4)
<br><br>

## ğŸŒ€ ë¬¸ì œ 3 í˜¸ëª¨ê·¸ë˜í”¼ë¥¼ ì´ìš©í•œ ì´ë¯¸ì§€ ì •í•©í•©

> ì‚¬ìš©ìê°€ ì§€ì •í•œ ì˜ì—­ì„ ë°”íƒ•ìœ¼ë¡œ **GrabCut ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ê°ì²´ ì¶”ì¶œ**
> ê°ì²´ ì¶”ì¶œ ê²°ê³¼ë¥¼ ë§ˆìŠ¤í¬ í˜•íƒœë¡œ ì‹œê°í™” í›„ ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ ë°°ê²½ì„ ì œê±°í•˜ê³  ê°ì²´ë§Œ ë‚¨ì€ ì´ë¯¸ì§€ë¥¼ ì¶œë ¥
---

### ğŸ“„ ì½”ë“œ 
- Grabcut.py

*ì „ì²´ ì½”ë“œ*
```python
import cv2 as cv
import numpy as np

img1 = cv.imread('img1.jpg')
img2 = cv.imread('img2.jpg')   


gray1 = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)
gray2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)

sift = cv.SIFT_create()
kp1, des1 = sift.detectAndCompute(gray1, None)
kp2, des2 = sift.detectAndCompute(gray2, None)

bf = cv.BFMatcher(cv.NORM_L2, crossCheck=False)
matches = bf.knnMatch(des1, des2, k=2)

good_matches = []
ratio_thresh = 0.7
for m, n in matches:
    if m.distance < ratio_thresh * n.distance:
        good_matches.append(m)

print("matching num :", len(good_matches))

src_pts = np.float32([ kp1[m.queryIdx].pt for m in good_matches ]).reshape(-1, 1, 2)
dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good_matches ]).reshape(-1, 1, 2)

H, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC)

h2, w2 = img2.shape[:2]
warped_img = cv.warpPerspective(img1, H, (w2, h2))

cv.imshow("original", img2)
cv.imshow("Warped images", warped_img)

img_matches = cv.drawMatches(img1, kp1, img2, kp2, good_matches, None,
                             flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)
cv.imshow("matching result", img_matches)

cv.waitKey(0)
cv.destroyAllWindows()
```

*í•µì‹¬ ì½”ë“œ* <br>
**ğŸ”· ë³€ìˆ˜ ì´ˆê¸°í™”**
```python
mask = np.zeros(img.shape[:2], np.uint8)
bgdModel = np.zeros((1, 65), np.float64)
fgdModel = np.zeros((1, 65), np.float64)
```
ğŸ”¹ Grapcutì—ì„œ ì‚¬ìš©í•  ë§ˆìŠ¤í¬ì™€ ë°±/í¬ì–´ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™” <br>
ğŸ”¹ pixel ë¶„í¬ë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•¨
<br><br>
**ğŸ”· ì‹œê°í™”í•˜ê¸° ìœ„í•œ ì˜ì—­ ì§€ì •**
```python
rect = (300, 300, 600, 500)
```
ğŸ”¹ (300, 300, 600, 500) ë²”ìœ„ì˜ ì‚¬ê°í˜• <br>
<br><br>
**ğŸ”· GrapCut ìˆ˜í–‰**
```python
cv.grabCut(img, mask, rect, bgdModel, fgdModel, 5, cv.GC_INIT_WITH_RECT)
```
ğŸ”¹ ë°˜ë³µ íšŸìˆ˜ë¥¼ 5ë²ˆìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ë” ì •êµí•˜ê²Œ ë¶„ë¦¬í•¨
<br><br>
**ğŸ”· Mask ì ìš©**
```python
mask2 = np.where((mask == cv.GC_BGD) | (mask == cv.GC_PR_BGD), 0, 1).astype('uint8')
img_result = img * mask2[:, :, np.newaxis]
```
ğŸ”¹ Maskë¥¼ ì ìš©í•˜ì—¬ ë°°ê²½ì´ ì œê±°ëœ ì´ë¯¸ì§€ ìƒì„± <br>
<br><br>
**ğŸ”· matplotlib ì‚¬ìš©ì„ ìœ„í•œ RGB image ë³€í™˜**
```python
img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)
img_result_rgb = cv.cvtColor(img_result, cv.COLOR_BGR2RGB)
```
ğŸ”¹ OpenCVëŠ” BGR imageì´ê³  matplotlibëŠ” RGB imageì´ê¸° ë•Œë¬¸ì— ë³€í™˜ <br>
<br><br>
### :octocat: ì‹¤í–‰ ê²°ê³¼

![ìŠ¤í¬ë¦°ìƒ· 2025-04-01 173214](https://github.com/user-attachments/assets/601d4fa9-79e7-430a-acdb-fd6a9ad6bb6b)
