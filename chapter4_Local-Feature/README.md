## ğŸŒ€ ë¬¸ì œ 1 SIFTë¥¼ ì´ìš©í•œ íŠ¹ì§•ì  ê²€ì¶œ ë° ì‹œê°í™”

> ì´ë¯¸ì§€ë¥¼ ì´ìš©í•˜ì—¬ **SIFT(Scale-Invariant Feature Transform) ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ íŠ¹ì§•ì ì„ ê²€ì¶œ**í•˜ê³  ì‹œê°í™”
---
**SIFT** <br><br>
![image](https://github.com/user-attachments/assets/9d856265-b7b2-4aa9-860c-2c1d87a9488c)

### ğŸ“„ ì½”ë“œ 
- SIFT.py

*ì „ì²´ ì½”ë“œ*
```python
import cv2 as cv
import matplotlib.pyplot as plt

img = cv.imread('mot_color70.jpg')
img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)

gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)

sift = cv.SIFT_create(nfeatures=0)  

kp, des = sift.detectAndCompute(gray, None)

img_kp = cv.drawKeypoints(img_rgb, kp, None, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.imshow(img_rgb)
plt.title('Original')
plt.axis('off')

plt.subplot(1, 2, 2)
plt.imshow(img_kp)
plt.title('SIFT result')
plt.axis('off')

plt.tight_layout()
plt.show()
```
*í•µì‹¬ì½”ë“œ* <br>
**ğŸ”· grayscale ì´ë¯¸ì§€ ë³€í™˜**
```python
gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
```
ğŸ”¹ SIFTëŠ” Grayscale ì´ë¯¸ì§€ì—ì„œ íŠ¹ì§•ì ì„ ì¶”ì¶œí•˜ë¯€ë¡œ Grayscale ë³€í™˜
<br><br>
**ğŸ”· SIFT ê°ì²´ ìƒì„±**
```python
sift = cv.SIFT_create(nfeatures=0)
```
ğŸ”¹ nfeatures=0 : ì¶”ì¶œí•  íŠ¹ì§•ì  ìˆ˜ì— ì œí•œì„ ë‘ì§€ ì•ŠìŒ
<br><br>
**ğŸ”· íŠ¹ì§•ì , ê¸°ìˆ ì ê³„ì‚°**
```python
kp, des = sift.detectAndCompute(gray, None)
```
ğŸ”¹ detectAndCompute() : íŠ¹ì§•ì (keypoints)ê³¼ descriptors ë™ì‹œì— ê³„ì‚°
<br><br>
**ğŸ”· íŠ¹ì§•ì  ì‹œê°í™”**
```python
img_kp = cv.drawKeypoints(img_rgb, kp, None, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
```
ğŸ”¹ íŠ¹ì§•ì ì„ ì´ë¯¸ì§€ì— ì‹œê°í™” <br>
ğŸ”¹ DRAW_RICH_KEYPOINTS : í¬ê¸°ì™€ ë°©í–¥ ì •ë³´ë¥¼ í¬í•¨í•´ ì›ìœ¼ë¡œ í‘œì‹œ
<br><br>
### :octocat: ì‹¤í–‰ ê²°ê³¼

![Figure 2025-04-01 152956](https://github.com/user-attachments/assets/a77544fc-b252-4442-af9c-71e016998634)
<br> SIFTëŠ” íŠ¹ì§•ì ì„ ê²€ì¶œí•  ë•Œ ë‹¨ìˆœíˆ x,yë§Œ ì°¾ì§€ ì•Šê³  íŠ¹ì§•ì  scaleê³¼ ë°©í–¥ë„ í•¨ê»˜ ì˜ˆì¸¡
<br> --> Scaleì˜ í¬ê¸°ì— ë”°ë¼ ì›ì˜ í¬ê¸°ê°€ ê²°ì •ë¨ (í° ìŠ¤ì¼€ì¼ì—ì„œëŠ” í° ì›, ì‘ì€ ìŠ¤ì¼€ì¼ì—ì„œëŠ” ì‘ì€ ì›)
<br><br>
## ğŸŒ€ ë¬¸ì œ 2 SIFTë¥¼ ì´ìš©í•œ ë‘ ì˜ìƒ ê°„ íŠ¹ì§•ì  ë§¤ì¹­

> ì£¼ì–´ì§„ ì´ë¯¸ì§€ë¥¼ **SIFT íŠ¹ì§•ì  ê¸°ë°˜ìœ¼ë¡œ ë§¤ì¹­ ìˆ˜í–‰**
---

### ğŸ“„ ì½”ë“œ 
- SIFT_match.py

*ì „ì²´ ì½”ë“œ*
```python
import cv2 as cv
import numpy as np
import time
import matplotlib.pyplot as plt

img1 = cv.imread('mot_color70.jpg')
img1 = img1[190:350, 440:560]  

img2 = cv.imread('mot_color83.jpg')

gray1 = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)
gray2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)

sift = cv.SIFT_create()
kp1, des1 = sift.detectAndCompute(gray1, None)
kp2, des2 = sift.detectAndCompute(gray2, None)
print('Feature :', len(kp1), len(kp2))

start = time.time()
flann = cv.DescriptorMatcher_create(cv.DescriptorMatcher_FLANNBASED)
knn_match = flann.knnMatch(des1, des2, 2)

T = 0.7
good_match = []
for nearest1, nearest2 in knn_match:
    if (nearest1.distance / nearest2.distance) < T:
        good_match.append(nearest1)
print('Time :', time.time() - start)

img_match = cv.drawMatches(img1, kp1, img2, kp2, good_match, None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

img_match_rgb = cv.cvtColor(img_match, cv.COLOR_BGR2RGB)

plt.figure(figsize=(12, 6))
plt.imshow(img_match_rgb)
plt.title('FLANN result')
plt.axis('off')
plt.show()
```

*í•µì‹¬ ì½”ë“œ* <br>
**ğŸ”· ROIë¥¼ ì˜ë¼ë‚´ê³  ë¹„êµ ëŒ€ìƒì„ ë¶ˆëŸ¬ì˜´**
```python
img1 = cv.imread('mot_color70.jpg')
img1 = img1[190:350, 440:560]

img2 = cv.imread('mot_color83.jpg')
```
ğŸ”¹ ì²«ë²ˆì§¸ ì´ë¯¸ì§€ì—ì„œ íŠ¹ì • ROIë¥¼ ì˜ë¼ëƒ„ <br>
ğŸ”¹ ë¹„êµ ëŒ€ìƒì´ ë˜ëŠ” ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜´
<br><br>
**ğŸ”· grayscale ì´ë¯¸ì§€ ë³€í™˜**
```python
gray1 = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)
gray2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)
```
ğŸ”¹ SIFT ì—°ì‚°ì„ ìœ„í•œ ë‘ ì´ë¯¸ì§€ grayscale ë³€í™˜
<br><br>
**ğŸ”· SIFT ìˆ˜í–‰**
```python
sift = cv.SIFT_create()
kp1, des1 = sift.detectAndCompute(gray1, None)
kp2, des2 = sift.detectAndCompute(gray2, None)
```
ğŸ”¹ SIFTë¥¼ í†µí•´ íŠ¹ì§•ì ê³¼ descriptors ì¶”ì¶œ
<br><br>
**ğŸ”· ë§¤ì¹­ ì—°ì‚°**
```python
flann = cv.DescriptorMatcher_create(cv.DescriptorMatcher_FLANNBASED)
knn_match = flann.knnMatch(des1, des2, 2)
```
ğŸ”¹ FLANN ê¸°ë°˜ ë§¤ì¹­ ê°ì²´ ìƒì„± í›„ KNN ë§¤ì¹­ ìˆ˜í–‰ (k=2) <br>
ğŸ”¹ ê° íŠ¹ì§•ì ì— ëŒ€í•´ ê°€ì¥ ê°€ê¹Œìš´ 2ê°œì˜ í›„ë³´ë¥¼ ì°¾ìŒ
<br><br>
**ğŸ”· ì„ê³„ê°’ ì„¤ì •**
```python
T = 0.7
good_match = []
for nearest1, nearest2 in knn_match:
    if (nearest1.distance / nearest2.distance) < T:
        good_match.append(nearest1)
```
ğŸ”¹ ë‘ í›„ë³´ì˜ ê±°ë¦¬ ë¹„ìœ¨ì´ ì„ê³„ê°’ë³´ë‹¤ ì‘ì„ ë•Œë§Œ ì¢‹ì€ ë§¤ì¹­ìœ¼ë¡œ íŒë‹¨
<br><br>
### :octocat: ì‹¤í–‰ ê²°ê³¼

![Figure 2025-04-01 165852](https://github.com/user-attachments/assets/31428164-9548-42ba-be5f-338a7b7044e4)
<br><br>

## ğŸŒ€ ë¬¸ì œ 3 í˜¸ëª¨ê·¸ë˜í”¼ë¥¼ ì´ìš©í•œ ì´ë¯¸ì§€ ì •í•©

> SIFT íŠ¹ì§•ì ì„ ì‚¬ìš©í•˜ì—¬ ë‘ ì´ë¯¸ì§€ ê°„ ëŒ€ì‘ì ì„ ì°¾ê³  **í˜¸ëª¨ê·¸ë˜í”¼ë¥¼ ê³„ì‚°í•˜ì—¬ í•˜ë‚˜ì˜ ì´ë¯¸ì§€ ìœ„ì— ì •ë ¬**
---

### ğŸ“„ ì½”ë“œ 
- SIFT_Homography.py

*ì „ì²´ ì½”ë“œ*
```python
import cv2 as cv
import numpy as np

img1 = cv.imread('img2.jpg')
img2 = cv.imread('img3.jpg')   


gray1 = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)
gray2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)

sift = cv.SIFT_create()
kp1, des1 = sift.detectAndCompute(gray1, None)
kp2, des2 = sift.detectAndCompute(gray2, None)

bf = cv.BFMatcher(cv.NORM_L2, crossCheck=False)
matches = bf.knnMatch(des1, des2, k=2)

good_matches = []
ratio_thresh = 0.7
for m, n in matches:
    if m.distance < ratio_thresh * n.distance:
        good_matches.append(m)

print("matching num :", len(good_matches))

src_pts = np.float32([ kp1[m.queryIdx].pt for m in good_matches ]).reshape(-1, 1, 2)
dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good_matches ]).reshape(-1, 1, 2)

H, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC)

h2, w2 = img2.shape[:2]
warped_img = cv.warpPerspective(img1, H, (w2, h2))

cv.imshow("original", img2)
cv.imshow("Warped images", warped_img)

img_matches = cv.drawMatches(img2, kp1, warped_img, kp2, good_matches, None,
                             flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)
cv.imshow("matching result", img_matches)

cv.waitKey(0)
cv.destroyAllWindows()
```

*í•µì‹¬ ì½”ë“œ* <br>
**ğŸ”· Grayscale ì´ë¯¸ì§€ ë³€í™˜**
```python
gray1 = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)
gray2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)
```
ğŸ”¹ SIFT ì—°ì‚°ì„ ìœ„í•´ Grayscale ì´ë¯¸ì§€ ë³€í™˜
<br><br>
**ğŸ”· SIFT ìˆ˜í–‰**
```python
sift = cv.SIFT_create()
kp1, des1 = sift.detectAndCompute(gray1, None)
kp2, des2 = sift.detectAndCompute(gray2, None)
```
ğŸ”¹ ë‘ ì´ë¯¸ì§€ì—ì„œ íŠ¹ì§•ì ê³¼ desscriptor ì¶”ì¶œ <br>
<br><br>
**ğŸ”· KNN matching ìˆ˜í–‰**
```python
bf = cv.BFMatcher(cv.NORM_L2, crossCheck=False)
matches = bf.knnMatch(des1, des2, k=2)
```
ğŸ”¹ BFMatcher(Brute-Force Matcher)ë¥¼ ì‚¬ìš©í•˜ì—¬ destriptors ê°„ KNN ë§¤ì¹­(k=2)ì„ ìˆ˜í–‰
<br><br>
**ğŸ”· Matching í•„í„°ë§**
```python
good_matches = []
ratio_thresh = 0.7
for m, n in matches:
    if m.distance < ratio_thresh * n.distance:
        good_matches.append(m)
```
ğŸ”¹ ì˜ëª»ëœ ë§¤ì¹­ì„ ì œê±°í•˜ì—¬ ì‹ ë¢°ì„±ì„ ë†’ì„ <br>
<br><br>
**ğŸ”· ì‹¤ì œ ì¢Œí‘œ ì¶”ì¶œ**
```python
src_pts = np.float32([ kp1[m.queryIdx].pt for m in good_matches ]).reshape(-1, 1, 2)
dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good_matches ]).reshape(-1, 1, 2)
```
ğŸ”¹ ë§¤ì¹­ì ì—ì„œ ì‹¤ì œ ì¢Œí‘œë¥¼ ì¶”ì¶œí•˜ì—¬ í˜¸ëª¨ê·¸ë˜í”¼ ê³„ì‚°ì„ ìœ„í•œ ë°ì´í„°ë¡œ ë³€í™˜ <br>
<br><br>
**ğŸ”· í˜¸ëª¨ê·¸ë˜í”¼ ì¶”ì •**
```python
H, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC)
```
ğŸ”¹ RANSAC ê¸°ë°˜ìœ¼ë¡œ í˜¸ëª¨ê·¸ë˜í”¼ í–‰ë ¬ì„ ì¶”ì • <br>
<br><br>
**ğŸ”· ì´ë¯¸ì§€ ì •ë ¬ í›„ ì‹œê°ì  í‘œì‹œ**
```python
warped_img = cv.warpPerspective(img1, H, (w2, h2))

img_matches = cv.drawMatches(img2, kp1, warped_img, kp2, good_matches, None,
                             flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)
```
ğŸ”¹ ì¶”ì •ëœ í˜¸ëª¨ê·¸ë˜í”¼ë¥¼ ì´ìš©í•˜ì—¬ img1, img2ì— ì •ë ¬ë˜ë„ë¡ ë³€í˜• <br>
ğŸ”¹ ë§¤ì¹­ ê²°ê³¼ë¥¼ ì‹œê°í™”
<br><br>
### :octocat: ì‹¤í–‰ ê²°ê³¼

![Uploading image.pngâ€¦]()

