## ğŸŒ€ ë¬¸ì œ 1 SORT ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•œ ë‹¤ì¤‘ ê°ì²´ ì¶”ì ê¸° êµ¬í˜„
> YOLOv3ì„ ì‚¬ìš©í•˜ì—¬ Detection í›„ **Sort ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ Tracking**
> sort.py ì•ˆì— êµ¬í˜„ëœ sort ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©
---
**SORT ì•Œê³ ë¦¬ì¦˜** <br><br>


### ğŸ“„ ì½”ë“œ 
- Sort_Tracking.py

*ì „ì²´ ì½”ë“œ*
```python
import numpy as np
import cv2 as cv
import sys

def construct_yolo_v3():
    f=open('coco_names.txt', 'r')
    class_names=[line.strip() for line in f.readlines()]

    model=cv.dnn.readNet('yolov3.weights','yolov3.cfg')
    layer_names=model.getLayerNames()
    out_layers=[layer_names[i-1] for i in model.getUnconnectedOutLayers()]
    
    return model,out_layers,class_names

def yolo_detect(img,yolo_model,out_layers):
    height,width=img.shape[0],img.shape[1]
    test_img=cv.dnn.blobFromImage(img,1.0/256,(448,448),(0,0,0),swapRB=True)
    
    yolo_model.setInput(test_img)
    output3=yolo_model.forward(out_layers)
    
    box,conf,id=[],[],[]		# ë°•ìŠ¤, ì‹ ë¢°ë„, ë¶€ë¥˜ ë²ˆí˜¸
    for output in output3:
        for vec85 in output:
            scores=vec85[5:]
            class_id=np.argmax(scores)
            confidence=scores[class_id]
            if confidence>0.5:	# ì‹ ë¢°ë„ê°€ 50% ì´ìƒì¸ ê²½ìš°ë§Œ ì·¨í•¨
                centerx,centery=int(vec85[0]*width),int(vec85[1]*height)
                w,h=int(vec85[2]*width),int(vec85[3]*height)
                x,y=int(centerx-w/2),int(centery-h/2)
                box.append([x,y,x+w,y+h])
                conf.append(float(confidence))
                id.append(class_id)
            
    ind=cv.dnn.NMSBoxes(box,conf,0.5,0.4)
    objects=[box[i]+[conf[i]]+[id[i]] for i in range(len(box)) if i in ind]
    return objects

model,out_layers,class_names=construct_yolo_v3()	# YOLO ëª¨ë¸ ìƒì„±
colors=np.random.uniform(0,255,size=(100,3))		# 100ê°œ ìƒ‰ìœ¼ë¡œ íŠ¸ë™ êµ¬ë¶„

from sort import Sort

sort=Sort()

cap=cv.VideoCapture(0,cv.CAP_DSHOW)
if not cap.isOpened(): sys.exit('ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨')

while True:
    ret,frame=cap.read()
    if not ret: sys.exit('í”„ë ˆì„ íšë“ì— ì‹¤íŒ¨í•˜ì—¬ ë£¨í”„ë¥¼ ë‚˜ê°‘ë‹ˆë‹¤.')
        
    res=yolo_detect(frame,model,out_layers)   
    persons=[res[i] for i in range(len(res)) if res[i][5]==0]

    if len(persons)==0: 
        tracks=sort.update()
    else:
        tracks=sort.update(np.array(persons))
    
    for i in range(len(tracks)):
        x1,y1,x2,y2,track_id=tracks[i].astype(int)
        cv.rectangle(frame,(x1,y1),(x2,y2),colors[track_id],2)
        cv.putText(frame,str(track_id),(x1+10,y1+40),cv.FONT_HERSHEY_PLAIN,3,colors[track_id],2)            
    
    cv.imshow('Person tracking by SORT',frame)
    
    key=cv.waitKey(1) 
    if key==ord('q'): break 
    
cap.release()		# ì¹´ë©”ë¼ì™€ ì—°ê²°ì„ ëŠìŒ
cv.destroyAllWindows()
```
*í•µì‹¬ì½”ë“œ* <br>
**ğŸ”· YOLOv3, COCO datasets ë¡œë“œ**
```python
def construct_yolo_v3():
    f=open('coco_names.txt', 'r')
    class_names=[line.strip() for line in f.readlines()]

    model=cv.dnn.readNet('yolov3.weights','yolov3.cfg')
    layer_names=model.getLayerNames()
    out_layers=[layer_names[i-1] for i in model.getUnconnectedOutLayers()]
    
    return model,out_layers,class_names
```
ğŸ”¹ COCO datasetì— í¬í•¨ëœ í´ë˜ìŠ¤ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥ <br>
ğŸ”¹ Trainëœ YOLOv3 ëª¨ë¸ì˜ weightì™€ configë¥¼ ë¶ˆëŸ¬ì˜´
<br><br>
**ğŸ”· Input images Preprocessing**
```python
test_img=cv.dnn.blobFromImage(img,1.0/256,(448,448),(0,0,0),swapRB=True)
```
ğŸ”¹ OpenCVì—ì„œ ì§€ì›í•˜ëŠ” blob í˜•íƒœë¡œ ë³€í™˜ <br>
ğŸ”¹ pixel ì •ê·œí™” ë° í¬ê¸° ë³€í™˜, ì±„ë„ ìˆœì„œ ë³€ê²½
<br><br>
**ğŸ”· YOLOv3ë¡œ Object Detection**
```python
yolo_model.setInput(test_img)
output3=yolo_model.forward(out_layers)
```
ğŸ”¹ YOLOv3ìœ¼ë¡œ Detectionì„ ìˆ˜í–‰í•˜ì—¬ bbox ì˜ˆì¸¡ê°’ íšë“
<br><br>
**ğŸ”· ì‹ ë¢°ë„ ê¸°ë°˜ ê°ì²´ í•„í„°ë§**
```python
 if confidence>0.5:	# ì‹ ë¢°ë„ê°€ 50% ì´ìƒì¸ ê²½ìš°ë§Œ ì·¨í•¨
    centerx,centery=int(vec85[0]*width),int(vec85[1]*height)
    w,h=int(vec85[2]*width),int(vec85[3]*height)
    x,y=int(centerx-w/2),int(centery-h/2)
    box.append([x,y,x+w,y+h])
    conf.append(float(confidence))
    id.append(class_id)
```
ğŸ”¹ Confidenceê°€ 50% ì´ìƒì¸ ì˜ˆì¸¡ê°’ë§Œ í‘œì‹œ <br>
ğŸ”¹ Detectionëœ ê°ì²´ì˜ ìœ„ì¹˜, í™•ë¥ , í´ë˜ìŠ¤ ì •ë³´ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥
<br><br>
**ğŸ”· NMS(Non-Maximum Suppression) ì ìš©**
```python
ind = cv.dnn.NMSBoxes(box, conf, 0.5, 0.4)
objects = [box[i] + [conf[i]] + [id[i]] for i in range(len(box)) if i in ind]
```
ğŸ”¹ ê²¹ì¹˜ëŠ” ì˜ˆì¸¡ bbox ì¤‘ í™•ë¥ ì´ ê°€ì¥ ë†’ì€ ê²ƒë§Œ ì„ íƒí•˜ì—¬ ìµœì¢… bbox ìƒì„±
<br><br>
**ğŸ”· Persons classë§Œ Detection**
```python
persons=[res[i] for i in range(len(res)) if res[i][5]==0]
```
ğŸ”¹ class ë²ˆí˜¸ê°€ 0ì¸ person ê°ì²´ë§Œ Detection í›„ Tracking
<br><br>
**ğŸ”· Sort ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•œ Traking**
```python
if len(persons)==0:
        tracks=sort.update()
    else:
        tracks=sort.update(np.array(persons))
```
ğŸ”¹ í”„ë ˆì„ë³„ë¡œ ê°ì§€ëœ ì‚¬ëŒ ìœ„ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Kalman Filter, Hungarian Algorithmìœ¼ë¡œ ID ë¶€ì—¬ ë° Tracking
<br><br>
**ğŸ”· ê²°ê³¼ ì¶œë ¥**
```python
cv.rectangle(frame, (x1, y1), (x2, y2), colors[track_id], 2)
cv.putText(frame, str(track_id), (x1+10, y1+40), cv.FONT_HERSHEY_PLAIN, 3, colors[track_id], 2)
```
ğŸ”¹ ê³ ìœ í•œ ìƒ‰ìƒê³¼ IDë¥¼ ì‚¬ìš©í•˜ì—¬ frame ìœ„ì— ì‹œê°ì  í‘œì‹œ
ğŸ”¹ ê° Trackingëœ ëŒ€ìƒì— ê³ ìœ í•œ ë²ˆí˜¸ë¥¼ ë¶€ì—¬
<br><br>
### :octocat: ì‹¤í–‰ ê²°ê³¼
![ìŠ¤í¬ë¦°ìƒ· 2025-04-15 174213](https://github.com/user-attachments/assets/f59f3bc2-14bc-4eea-ac4e-4965b1fcf6ee)
<br><br>
## ğŸŒ€ ë¬¸ì œ 2 Mediapipeë¥¼ í™œìš©í•œ ì–¼êµ´ ëœë“œë§ˆí¬ ì¶”ì¶œ ë° ì‹œê°í™”

> Mediapipeì˜ FaceMeshëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ì–¼êµ´ì˜ 468ê°œì˜ ëœë“œë§ˆí¬ë¥¼ ì¶”ì¶œí•˜ê³  ì‹¤ì‹œê°„ ì˜ìƒì— ì‹œê°í™”í•˜ëŠ” í”„ë¡œê·¸ë¨ êµ¬í˜„
---
**Mediapipe** <br><br>

### ğŸ“„ ì½”ë“œ 
- CIFAR10-CNN.py

*ì „ì²´ ì½”ë“œ*
```python
import cv2 as cv
import mediapipe as mp

mp_mesh=mp.solutions.face_mesh
mp_drawing=mp.solutions.drawing_utils
mp_styles=mp.solutions.drawing_styles

mesh=mp_mesh.FaceMesh(max_num_faces=2,refine_landmarks=True,min_detection_confidence=0.5,min_tracking_confidence=0.5)

cap=cv.VideoCapture(0,cv.CAP_DSHOW)

while True:
    ret,frame=cap.read()
    if not ret:
      print('í”„ë ˆì„ íšë“ì— ì‹¤íŒ¨í•˜ì—¬ ë£¨í”„ë¥¼ ë‚˜ê°‘ë‹ˆë‹¤.')
      break
    
    res=mesh.process(cv.cvtColor(frame,cv.COLOR_BGR2RGB))
    
    if res.multi_face_landmarks:
        for landmarks in res.multi_face_landmarks:
          mp_drawing.draw_landmarks(image=frame,landmark_list=landmarks,connections=mp_mesh.FACEMESH_CONTOURS,landmark_drawing_spec=mp_drawing.DrawingSpec(thickness=1,circle_radius=1))
        
    cv.imshow('MediaPipe Face Mesh',cv.flip(frame,1))
    if cv.waitKey(5)==ord('q'):
      break

cap.release()
cv.destroyAllWindows()
```

*í•µì‹¬ ì½”ë“œ* <br>
**ğŸ”· ë°ì´í„°ì…‹ ë¡œë“œ**
```python
(x_train, y_train), (x_test, y_test) = ds.cifar10.load_data()
```
ğŸ”¹ tensorflow.keras.datasets ëª¨ë“ˆì˜ cifar10 ë°ì´í„°ì…‹ì„ ì‚¬ìš© <br>
ğŸ”¹ CIFAR-10 : 32Ã—32 í¬ê¸°ì˜ 60,000ê°œ ì»¬ëŸ¬ ì´ë¯¸ì§€, 10ê°œì˜ í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜
<br><br>
**ğŸ”· Normalization**
```python
mesh=mp_mesh.FaceMesh(max_num_faces=2,refine_landmarks=True,min_detection_confidence=0.5,min_tracking_confidence=0.5)
```
ğŸ”¹ ìµœëŒ€ 2ëª…ì˜ face detection <br>
ğŸ”¹ refine_landmarks=Trueë¥¼ ì‚¬ìš©í•˜ì—¬ ëˆˆë™ì, ì…ìˆ , í™ì±„ ë“± ì„¸ë°€í•œ í¬ì¸íŠ¸ë„ í¬í•¨ <br>
ğŸ”¹ Detection, Tracking ì‹ ë¢°ë„ë¥¼ 0.5ë¡œ ì„¤ì •í•˜ì—¬ 50% ì´ìƒì¼ ë•Œë§Œ ì ìš©
<br><br>
**ğŸ”· í”„ë ˆì„ íšë“ ë° ì „ì²˜ë¦¬**
```python
ret, frame = cap.read()
res = mesh.process(cv.cvtColor(frame, cv.COLOR_BGR2RGB))
```
ğŸ”¹ OpenCVë¡œ ì›¹ìº ì—ì„œ í”„ë ˆì„ì„ ì½ê³  BGR --> RGBë¡œ ë³€í™˜ í›„ FaceMeshë¡œ ì²˜ë¦¬
<br><br>
**ğŸ”· ëœë“œë§ˆí¬ ì‹œê°í™”**
```python
for landmarks in res.multi_face_landmarks:
    mp_drawing.draw_landmarks(
        image=frame,
        landmark_list=landmarks,
        connections=mp_mesh.FACEMESH_CONTOURS,
        landmark_drawing_spec=mp_drawing.DrawingSpec(thickness=1, circle_radius=1)
    )
```
ğŸ”¹ Detectionëœ faceì˜ ëœë“œë§ˆí¬ 468ê°œë¥¼ ìœ¤ê³½ì„  í˜•íƒœë¡œ ê·¸ë¦¼ <br>
ğŸ”¹ FACEMESH_CONTOURSë¥¼ í†µí•´ ëˆˆ, ì…, ì–¼êµ´ ì™¸ê³½ì„ ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì„ ì„ ì—°ê²° 
<br><br>
**ğŸ”· ê²°ê³¼ ì¶œë ¥**
```python
cv.imshow('MediaPipe Face Mesh', cv.flip(frame, 1))
```
ğŸ”¹ ì‹¤ì‹œê°„ìœ¼ë¡œ face meshë¥¼ ì‹œê°í™”
<br><br>
### :octocat: ì‹¤í–‰ ê²°ê³¼
![ìŠ¤í¬ë¦°ìƒ· 2025-04-15 185108](https://github.com/user-attachments/assets/80282387-ae19-450d-8e2f-d8a832bcdfa1)


