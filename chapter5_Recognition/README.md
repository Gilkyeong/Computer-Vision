## ğŸŒ€ ë¬¸ì œ 1 ê°„ë‹¨í•œ ì´ë¯¸ì§€ ë¶„ë¥˜ê¸° êµ¬í˜„

> MNIST datasetsì„ ì´ìš©í•˜ì—¬ **MLP êµ¬í˜„**
---
**MLP(Multi Layer Perceptron)** <br><br>
![image](https://github.com/user-attachments/assets/87b523bb-a531-4def-bab3-38eec11c9a4b)

### ğŸ“„ ì½”ë“œ 
- MNIST_MLP.py

*ì „ì²´ ì½”ë“œ*
```python
import numpy as np
import tensorflow as tf
import tensorflow.keras.datasets as ds

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

(x_train,y_train),(x_test,y_test)=ds.mnist.load_data()
x_train=x_train.reshape(60000,784)
x_test=x_test.reshape(10000,784)
x_train=x_train.astype(np.float32)/255.0
x_test=x_test.astype(np.float32)/255.0
y_train=tf.keras.utils.to_categorical(y_train,10)
y_test=tf.keras.utils.to_categorical(y_test,10)

dmlp=Sequential()
dmlp.add(Dense(units=1024,activation='relu',input_shape=(784,)))
dmlp.add(Dense(units=512,activation='relu'))
dmlp.add(Dense(units=512,activation='relu'))
dmlp.add(Dense(units=10,activation='softmax'))

dmlp.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate=0.0001),metrics=['accuracy'])
hist=dmlp.fit(x_train,y_train,batch_size=128,epochs=30,validation_data=(x_test,y_test),verbose=2)
print('acc =', dmlp.evaluate(x_test,y_test,verbose=0)[1]*100)

import matplotlib.pyplot as plt

plt.plot(hist.history['accuracy'])
plt.plot(hist.history['val_accuracy'])
plt.title('Accuracy graph')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend(['train','test'])
plt.grid()
plt.show()

plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title('Loss graph')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend(['train','test'])
plt.grid()
plt.show()
```
*í•µì‹¬ì½”ë“œ* <br>
**ğŸ”· grayscale ì´ë¯¸ì§€ ë³€í™˜**
```python
gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
```
ğŸ”¹ SIFTëŠ” Grayscale ì´ë¯¸ì§€ì—ì„œ íŠ¹ì§•ì ì„ ì¶”ì¶œí•˜ë¯€ë¡œ Grayscale ë³€í™˜
<br><br>
**ğŸ”· SIFT ê°ì²´ ìƒì„±**
```python
sift = cv.SIFT_create(nfeatures=0)
```
ğŸ”¹ nfeatures=0 : ì¶”ì¶œí•  íŠ¹ì§•ì  ìˆ˜ì— ì œí•œì„ ë‘ì§€ ì•ŠìŒ
<br><br>
**ğŸ”· íŠ¹ì§•ì , ê¸°ìˆ ì ê³„ì‚°**
```python
kp, des = sift.detectAndCompute(gray, None)
```
ğŸ”¹ detectAndCompute() : íŠ¹ì§•ì (keypoints)ê³¼ descriptors ë™ì‹œì— ê³„ì‚°
<br><br>
**ğŸ”· ì •í™•ë„ ì¸¡ì •**
```python
img_kp = cv.drawKeypoints(img_rgb, kp, None, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
```
ğŸ”¹ íŠ¹ì§•ì ì„ ì´ë¯¸ì§€ì— ì‹œê°í™” <br>
ğŸ”¹ DRAW_RICH_KEYPOINTS : í¬ê¸°ì™€ ë°©í–¥ ì •ë³´ë¥¼ í¬í•¨í•´ ì›ìœ¼ë¡œ í‘œì‹œ
![ìŠ¤í¬ë¦°ìƒ· 2025-04-08 162656](https://github.com/user-attachments/assets/06d48ed4-ece3-415d-9d32-44c3b7f52a5b)
<br><br>
### :octocat: ì‹¤í–‰ ê²°ê³¼

![mlpacc](https://github.com/user-attachments/assets/44c99f1f-3298-4d63-84ab-726f35b49525)
![mlploss](https://github.com/user-attachments/assets/d8f61503-93e9-4e1d-bce9-52807eb33be2)
<br><br>
## ğŸŒ€ ë¬¸ì œ 2 CIFAR-10 datasetsì„ í™œìš©í•œ CNN ëª¨ë¸ êµ¬ì¶•

> CIFAR-10 datasetsì„ í™œìš©í•˜ì—¬ **CNNì„ êµ¬ì¶•í•˜ê³  image classification ìˆ˜í–‰**
---
**CNN(Convolutional Neural Network)** <br><br>
![image](https://github.com/user-attachments/assets/d49fd4e0-cd3a-482e-9158-47d99863e7be)

### ğŸ“„ ì½”ë“œ 
- CIFAR10-CNN.py

*ì „ì²´ ì½”ë“œ*
```python
import numpy as np
import tensorflow as tf
import tensorflow.keras.datasets as ds

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout
from tensorflow.keras.optimizers import Adam

(x_train,y_train),(x_test,y_test)=ds.cifar10.load_data()
x_train=x_train.astype(np.float32)/255.0
x_test=x_test.astype(np.float32)/255.0
y_train=tf.keras.utils.to_categorical(y_train,10)
y_test=tf.keras.utils.to_categorical(y_test,10)

cnn=Sequential()
cnn.add(Conv2D(32,(3,3),activation='relu',input_shape=(32,32,3)))
cnn.add(Conv2D(32,(3,3),activation='relu'))
cnn.add(MaxPooling2D(pool_size=(2,2)))
cnn.add(Dropout(0.25))
cnn.add(Conv2D(64,(3,3),activation='relu'))
cnn.add(Conv2D(64,(3,3),activation='relu'))
cnn.add(MaxPooling2D(pool_size=(2,2)))
cnn.add(Dropout(0.25))
cnn.add(Flatten())
cnn.add(Dense(units=512,activation='relu'))
cnn.add(Dropout(0.5))
cnn.add(Dense(units=10,activation='softmax'))

cnn.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate=0.001),metrics=['accuracy'])
hist=cnn.fit(x_train,y_train,batch_size=128,epochs=50,validation_data=(x_test,y_test),verbose=2)

res=cnn.evaluate(x_test,y_test,verbose=0)
print('acc =',res[1]*100)

import matplotlib.pyplot as plt

plt.plot(hist.history['accuracy'])
plt.plot(hist.history['val_accuracy'])
plt.title('Accuracy graph')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train','Validation'])
plt.grid()
plt.show()

plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title('Loss graph')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train','Validation'])
plt.grid()
plt.show()
```

*í•µì‹¬ ì½”ë“œ* <br>
**ğŸ”· ROIë¥¼ ì˜ë¼ë‚´ê³  ë¹„êµ ëŒ€ìƒì„ ë¶ˆëŸ¬ì˜´**
```python
img1 = cv.imread('mot_color70.jpg')
img1 = img1[190:350, 440:560]

img2 = cv.imread('mot_color83.jpg')
```
ğŸ”¹ ì²«ë²ˆì§¸ ì´ë¯¸ì§€ì—ì„œ íŠ¹ì • ROIë¥¼ ì˜ë¼ëƒ„ <br>
ğŸ”¹ ë¹„êµ ëŒ€ìƒì´ ë˜ëŠ” ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜´
<br><br>
**ğŸ”· grayscale ì´ë¯¸ì§€ ë³€í™˜**
```python
gray1 = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)
gray2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)
```
ğŸ”¹ SIFT ì—°ì‚°ì„ ìœ„í•œ ë‘ ì´ë¯¸ì§€ grayscale ë³€í™˜
<br><br>
**ğŸ”· SIFT ìˆ˜í–‰**
```python
sift = cv.SIFT_create()
kp1, des1 = sift.detectAndCompute(gray1, None)
kp2, des2 = sift.detectAndCompute(gray2, None)
```
ğŸ”¹ SIFTë¥¼ í†µí•´ íŠ¹ì§•ì ê³¼ descriptors ì¶”ì¶œ
<br><br>
**ğŸ”· ë§¤ì¹­ ì—°ì‚°**
```python
flann = cv.DescriptorMatcher_create(cv.DescriptorMatcher_FLANNBASED)
knn_match = flann.knnMatch(des1, des2, 2)
```
ğŸ”¹ FLANN ê¸°ë°˜ ë§¤ì¹­ ê°ì²´ ìƒì„± í›„ KNN ë§¤ì¹­ ìˆ˜í–‰ (k=2) <br>
ğŸ”¹ ê° íŠ¹ì§•ì ì— ëŒ€í•´ ê°€ì¥ ê°€ê¹Œìš´ 2ê°œì˜ í›„ë³´ë¥¼ ì°¾ìŒ
<br><br>
**ğŸ”· ì„ê³„ê°’ ì„¤ì •**
```python
T = 0.7
good_match = []
for nearest1, nearest2 in knn_match:
    if (nearest1.distance / nearest2.distance) < T:
        good_match.append(nearest1)
```
ğŸ”¹ ë‘ í›„ë³´ì˜ ê±°ë¦¬ ë¹„ìœ¨ì´ ì„ê³„ê°’ë³´ë‹¤ ì‘ì„ ë•Œë§Œ ì¢‹ì€ ë§¤ì¹­ìœ¼ë¡œ íŒë‹¨
<br><br>
### :octocat: ì‹¤í–‰ ê²°ê³¼

![Figure 2025-04-01 165852](https://github.com/user-attachments/assets/31428164-9548-42ba-be5f-338a7b7044e4)
<br><br>

## ğŸŒ€ ë¬¸ì œ 3 í˜¸ëª¨ê·¸ë˜í”¼ë¥¼ ì´ìš©í•œ ì´ë¯¸ì§€ ì •í•©

> SIFT íŠ¹ì§•ì ì„ ì‚¬ìš©í•˜ì—¬ ë‘ ì´ë¯¸ì§€ ê°„ ëŒ€ì‘ì ì„ ì°¾ê³  **í˜¸ëª¨ê·¸ë˜í”¼ë¥¼ ê³„ì‚°í•˜ì—¬ í•˜ë‚˜ì˜ ì´ë¯¸ì§€ ìœ„ì— ì •ë ¬**
---

### ğŸ“„ ì½”ë“œ 
- SIFT_Homography.py

*ì „ì²´ ì½”ë“œ*
```python
import cv2 as cv
import numpy as np
import matplotlib.pyplot as plt

img1 = cv.imread('img2.jpg')
img2 = cv.imread('img3.jpg')

gray1 = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)
gray2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)

sift = cv.SIFT_create()
kp1, des1 = sift.detectAndCompute(gray1, None)
kp2, des2 = sift.detectAndCompute(gray2, None)

bf = cv.BFMatcher()
matches = bf.knnMatch(des1, des2, k=2)
good_matches = []
for m, n in matches:
    if m.distance < 0.7 * n.distance:
        good_matches.append(m)

src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)
dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)

H_pan, mask_pan = cv.findHomography(dst_pts, src_pts, cv.RANSAC, 5.0)
h1, w1 = img1.shape[:2]
h2, w2 = img2.shape[:2]
corners_img2 = np.float32([[0, 0], [0, h2], [w2, h2], [w2, 0]]).reshape(-1, 1, 2)
warped_corners = cv.perspectiveTransform(corners_img2, H_pan)
all_corners = np.concatenate((warped_corners, np.float32([[0, 0], [0, h1], [w1, h1], [w1, 0]]).reshape(-1, 1, 2)), axis=0)
[xmin, ymin] = np.int32(all_corners.min(axis=0).ravel() - 0.5)
[xmax, ymax] = np.int32(all_corners.max(axis=0).ravel() + 0.5)
translation = [-xmin, -ymin]
T = np.array([[1, 0, translation[0]], [0, 1, translation[1]], [0, 0, 1]])
panorama = cv.warpPerspective(img2, T @ H_pan, (xmax - xmin, ymax - ymin))
panorama[translation[1]:translation[1] + h1, translation[0]:translation[0] + w1] = img1

bf2 = cv.BFMatcher(cv.NORM_L2, crossCheck=False)
matches2 = bf2.knnMatch(des1, des2, k=2)
good_matches2 = []
ratio_thresh = 0.7
for m, n in matches2:
    if m.distance < ratio_thresh * n.distance:
        good_matches2.append(m)
print("matching num :", len(good_matches2))
src_pts2 = np.float32([kp1[m.queryIdx].pt for m in good_matches2]).reshape(-1, 1, 2)
dst_pts2 = np.float32([kp2[m.trainIdx].pt for m in good_matches2]).reshape(-1, 1, 2)
H_match, mask_match = cv.findHomography(src_pts2, dst_pts2, cv.RANSAC)
warped_img = cv.warpPerspective(img2, H_match, (w1, h1))
img_matches = cv.drawMatches(img1, kp1, warped_img, kp2, good_matches2, None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

panorama_rgb = cv.cvtColor(panorama, cv.COLOR_BGR2RGB)
img_matches_rgb = cv.cvtColor(img_matches, cv.COLOR_BGR2RGB)

plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(panorama_rgb)
plt.axis('off')
plt.subplot(1, 2, 2)
plt.imshow(img_matches_rgb)
plt.axis('off')
plt.show()
```

*í•µì‹¬ ì½”ë“œ* <br>
**ğŸ”· Grayscale ì´ë¯¸ì§€ ë³€í™˜**
```python
gray1 = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)
gray2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)
```
ğŸ”¹ SIFT ì—°ì‚°ì„ ìœ„í•´ Grayscale ì´ë¯¸ì§€ ë³€í™˜
<br><br>
**ğŸ”· SIFT ìˆ˜í–‰**
```python
sift = cv.SIFT_create()
kp1, des1 = sift.detectAndCompute(gray1, None)
kp2, des2 = sift.detectAndCompute(gray2, None)
```
ğŸ”¹ ë‘ ì´ë¯¸ì§€ì—ì„œ íŠ¹ì§•ì ê³¼ desscriptor ì¶”ì¶œ <br>
<br><br>
**ğŸ”· KNN matching ìˆ˜í–‰**
```python
bf = cv.BFMatcher(cv.NORM_L2, crossCheck=False)
matches = bf.knnMatch(des1, des2, k=2)
```
ğŸ”¹ BFMatcher(Brute-Force Matcher)ë¥¼ ì‚¬ìš©í•˜ì—¬ destriptors ê°„ KNN ë§¤ì¹­(k=2)ì„ ìˆ˜í–‰
<br><br>
**ğŸ”· Matching í•„í„°ë§**
```python
good_matches = []
ratio_thresh = 0.7
for m, n in matches:
    if m.distance < ratio_thresh * n.distance:
        good_matches.append(m)
```
ğŸ”¹ ì˜ëª»ëœ ë§¤ì¹­ì„ ì œê±°í•˜ì—¬ ì‹ ë¢°ì„±ì„ ë†’ì„ <br>
<br><br>
**ğŸ”· ì‹¤ì œ ì¢Œí‘œ ì¶”ì¶œ**
```python
src_pts = np.float32([ kp1[m.queryIdx].pt for m in good_matches ]).reshape(-1, 1, 2)
dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good_matches ]).reshape(-1, 1, 2)
```
ğŸ”¹ ë§¤ì¹­ì ì—ì„œ ì‹¤ì œ ì¢Œí‘œë¥¼ ì¶”ì¶œí•˜ì—¬ í˜¸ëª¨ê·¸ë˜í”¼ ê³„ì‚°ì„ ìœ„í•œ ë°ì´í„°ë¡œ ë³€í™˜ <br>
<br><br>
**ğŸ”· í˜¸ëª¨ê·¸ë˜í”¼ ì¶”ì •**
```python
H, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC)
```
ğŸ”¹ RANSAC ê¸°ë°˜ìœ¼ë¡œ í˜¸ëª¨ê·¸ë˜í”¼ í–‰ë ¬ì„ ì¶”ì • <br>
<br><br>
**ğŸ”· ì´ë¯¸ì§€ ì •ë ¬ í›„ ì‹œê°ì  í‘œì‹œ**
```python
h2, w2 = img1.shape[:2]
warped_img = cv.warpPerspective(img2, H, (w2, h2))
img_matches = cv.drawMatches(img1, kp1, warped_img, kp2, good_matches, None,
                             flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)
```
ğŸ”¹ ì¶”ì •ëœ í˜¸ëª¨ê·¸ë˜í”¼ë¥¼ ì´ìš©í•˜ì—¬ img1, img2ì— ì •ë ¬ë˜ë„ë¡ ë³€í˜• <br>
ğŸ”¹ ë§¤ì¹­ ê²°ê³¼ë¥¼ ì‹œê°í™”
<br><br>
### :octocat: ì‹¤í–‰ ê²°ê³¼

![image](https://github.com/user-attachments/assets/7c7525dc-8db0-40aa-bf7e-2dcca67914f6)
