## ğŸŒ€ ë¬¸ì œ 1 ê°„ë‹¨í•œ ì´ë¯¸ì§€ ë¶„ë¥˜ê¸° êµ¬í˜„

> MNIST datasetsì„ ì´ìš©í•˜ì—¬ **MLP êµ¬í˜„**
---
**MLP(Multi Layer Perceptron)** <br><br>
![image](https://github.com/user-attachments/assets/87b523bb-a531-4def-bab3-38eec11c9a4b)

### ğŸ“„ ì½”ë“œ 
- MNIST_MLP.py

*ì „ì²´ ì½”ë“œ*
```python
import numpy as np
import tensorflow as tf
import tensorflow.keras.datasets as ds

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

(x_train,y_train),(x_test,y_test)=ds.mnist.load_data()
x_train=x_train.reshape(60000,784)
x_test=x_test.reshape(10000,784)
x_train=x_train.astype(np.float32)/255.0
x_test=x_test.astype(np.float32)/255.0
y_train=tf.keras.utils.to_categorical(y_train,10)
y_test=tf.keras.utils.to_categorical(y_test,10)

dmlp=Sequential()
dmlp.add(Dense(units=1024,activation='relu',input_shape=(784,)))
dmlp.add(Dense(units=512,activation='relu'))
dmlp.add(Dense(units=512,activation='relu'))
dmlp.add(Dense(units=10,activation='softmax'))

dmlp.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate=0.0001),metrics=['accuracy'])
hist=dmlp.fit(x_train,y_train,batch_size=128,epochs=30,validation_data=(x_test,y_test),verbose=2)
print('acc =', dmlp.evaluate(x_test,y_test,verbose=0)[1]*100)

import matplotlib.pyplot as plt

plt.plot(hist.history['accuracy'])
plt.plot(hist.history['val_accuracy'])
plt.title('Accuracy graph')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend(['train','test'])
plt.grid()
plt.show()

plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title('Loss graph')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend(['train','test'])
plt.grid()
plt.show()
```
*í•µì‹¬ì½”ë“œ* <br>
**ğŸ”· grayscale ì´ë¯¸ì§€ ë³€í™˜**
```python
gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
```
ğŸ”¹ SIFTëŠ” Grayscale ì´ë¯¸ì§€ì—ì„œ íŠ¹ì§•ì ì„ ì¶”ì¶œí•˜ë¯€ë¡œ Grayscale ë³€í™˜
<br><br>
**ğŸ”· SIFT ê°ì²´ ìƒì„±**
```python
sift = cv.SIFT_create(nfeatures=0)
```
ğŸ”¹ nfeatures=0 : ì¶”ì¶œí•  íŠ¹ì§•ì  ìˆ˜ì— ì œí•œì„ ë‘ì§€ ì•ŠìŒ
<br><br>
**ğŸ”· íŠ¹ì§•ì , ê¸°ìˆ ì ê³„ì‚°**
```python
kp, des = sift.detectAndCompute(gray, None)
```
ğŸ”¹ detectAndCompute() : íŠ¹ì§•ì (keypoints)ê³¼ descriptors ë™ì‹œì— ê³„ì‚°
<br><br>
**ğŸ”· ì •í™•ë„ ì¸¡ì •**
```python
img_kp = cv.drawKeypoints(img_rgb, kp, None, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
```
ğŸ”¹ íŠ¹ì§•ì ì„ ì´ë¯¸ì§€ì— ì‹œê°í™” <br>
ğŸ”¹ DRAW_RICH_KEYPOINTS : í¬ê¸°ì™€ ë°©í–¥ ì •ë³´ë¥¼ í¬í•¨í•´ ì›ìœ¼ë¡œ í‘œì‹œ <br>
![ìŠ¤í¬ë¦°ìƒ· 2025-04-08 162656](https://github.com/user-attachments/assets/06d48ed4-ece3-415d-9d32-44c3b7f52a5b)
<br><br>
### :octocat: ì‹¤í–‰ ê²°ê³¼

![mlpacc](https://github.com/user-attachments/assets/44c99f1f-3298-4d63-84ab-726f35b49525)
![mlploss](https://github.com/user-attachments/assets/d8f61503-93e9-4e1d-bce9-52807eb33be2)
<br><br>
## ğŸŒ€ ë¬¸ì œ 2 CIFAR-10 datasetsì„ í™œìš©í•œ CNN ëª¨ë¸ êµ¬ì¶•

> CIFAR-10 datasetsì„ í™œìš©í•˜ì—¬ **CNNì„ êµ¬ì¶•í•˜ê³  image classification ìˆ˜í–‰**
---
**CNN(Convolutional Neural Network)** <br><br>
![image](https://github.com/user-attachments/assets/d49fd4e0-cd3a-482e-9158-47d99863e7be)

### ğŸ“„ ì½”ë“œ 
- CIFAR10-CNN.py

*ì „ì²´ ì½”ë“œ*
```python
import numpy as np
import tensorflow as tf
import tensorflow.keras.datasets as ds
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import load_img, img_to_array

(x_train, y_train), (x_test, y_test) = ds.cifar10.load_data()
x_train = x_train.astype(np.float32) / 255.0
x_test = x_test.astype(np.float32) / 255.0
y_train = tf.keras.utils.to_categorical(y_train, 10)
y_test = tf.keras.utils.to_categorical(y_test, 10)

cnn = Sequential()
cnn.add(Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)))
cnn.add(Conv2D(32, (3,3), activation='relu'))
cnn.add(MaxPooling2D(pool_size=(2,2)))
cnn.add(Dropout(0.25))
cnn.add(Conv2D(64, (3,3), activation='relu'))
cnn.add(Conv2D(64, (3,3), activation='relu'))
cnn.add(MaxPooling2D(pool_size=(2,2)))
cnn.add(Dropout(0.25))
cnn.add(Flatten())
cnn.add(Dense(512, activation='relu'))
cnn.add(Dropout(0.5))
cnn.add(Dense(10, activation='softmax'))

cnn.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])
hist = cnn.fit(x_train, y_train,
               batch_size=128, epochs=50,
               validation_data=(x_test, y_test),
               verbose=2)

res = cnn.evaluate(x_test, y_test, verbose=0)
print('acc =', res[1]*100)

plt.plot(hist.history['accuracy'])
plt.plot(hist.history['val_accuracy'])
plt.title('Accuracy graph')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'])
plt.grid()
plt.show()

plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title('Loss graph')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'])
plt.grid()
plt.show()

test_img = load_img("dog.jpg", target_size=(32,32))
test_img_array = img_to_array(test_img)
test_img_array = test_img_array.astype(np.float32) / 255.0
test_img_array = np.expand_dims(test_img_array, axis=0)

prediction = cnn.predict(test_img_array)
predicted_class_idx = np.argmax(prediction, axis=1)[0]

class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 
               'dog', 'frog', 'horse', 'ship', 'truck']
print("Index :", predicted_class_idx)
print("Class name :", class_names[predicted_class_idx])
```

*í•µì‹¬ ì½”ë“œ* <br>
**ğŸ”· ROIë¥¼ ì˜ë¼ë‚´ê³  ë¹„êµ ëŒ€ìƒì„ ë¶ˆëŸ¬ì˜´**
```python
img1 = cv.imread('mot_color70.jpg')
img1 = img1[190:350, 440:560]

img2 = cv.imread('mot_color83.jpg')
```
ğŸ”¹ ì²«ë²ˆì§¸ ì´ë¯¸ì§€ì—ì„œ íŠ¹ì • ROIë¥¼ ì˜ë¼ëƒ„ <br>
ğŸ”¹ ë¹„êµ ëŒ€ìƒì´ ë˜ëŠ” ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜´
<br><br>
**ğŸ”· grayscale ì´ë¯¸ì§€ ë³€í™˜**
```python
gray1 = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)
gray2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)
```
ğŸ”¹ SIFT ì—°ì‚°ì„ ìœ„í•œ ë‘ ì´ë¯¸ì§€ grayscale ë³€í™˜
<br><br>
**ğŸ”· SIFT ìˆ˜í–‰**
```python
sift = cv.SIFT_create()
kp1, des1 = sift.detectAndCompute(gray1, None)
kp2, des2 = sift.detectAndCompute(gray2, None)
```
ğŸ”¹ SIFTë¥¼ í†µí•´ íŠ¹ì§•ì ê³¼ descriptors ì¶”ì¶œ
<br><br>
**ğŸ”· ë§¤ì¹­ ì—°ì‚°**
```python
flann = cv.DescriptorMatcher_create(cv.DescriptorMatcher_FLANNBASED)
knn_match = flann.knnMatch(des1, des2, 2)
```
ğŸ”¹ FLANN ê¸°ë°˜ ë§¤ì¹­ ê°ì²´ ìƒì„± í›„ KNN ë§¤ì¹­ ìˆ˜í–‰ (k=2) <br>
ğŸ”¹ ê° íŠ¹ì§•ì ì— ëŒ€í•´ ê°€ì¥ ê°€ê¹Œìš´ 2ê°œì˜ í›„ë³´ë¥¼ ì°¾ìŒ
<br><br>
**ğŸ”· ì •í™•ë„ ì¸¡ì •**
```python
res = cnn.evaluate(x_test, y_test, verbose=0)
print('acc =', res[1]*100)
```
ğŸ”¹  <br>
![image](https://github.com/user-attachments/assets/9f5199c4-ff25-44ed-8169-fe9229ab754f) <br>
**ğŸ”· ì´ë¯¸ì§€ classification**
```python
test_img = load_img("dog.jpg", target_size=(32,32))
test_img_array = img_to_array(test_img)
test_img_array = test_img_array.astype(np.float32) / 255.0
test_img_array = np.expand_dims(test_img_array, axis=0)

prediction = cnn.predict(test_img_array)
predicted_class_idx = np.argmax(prediction, axis=1)[0]

class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 
               'dog', 'frog', 'horse', 'ship', 'truck']
print("Index :", predicted_class_idx)
print("Class name :", class_names[predicted_class_idx])
```
ğŸ”¹ <br>
![ìŠ¤í¬ë¦°ìƒ· 2025-04-08 172139](https://github.com/user-attachments/assets/ac32b121-21ea-4102-8a6e-6d48c84a8112)
<br><br>
### :octocat: ì‹¤í–‰ ê²°ê³¼
![image](https://github.com/user-attachments/assets/d9c19ef9-f72d-4327-afc3-117acd25c23e)
![image](https://github.com/user-attachments/assets/90fdd4e7-a956-47da-a57b-2e82413cb981)
<br><br>

## ğŸŒ€ ë¬¸ì œ 3 ì „ì´ í•™ìŠµì„ í™œìš©í•œ ì´ë¯¸ì§€ ë¶„ë¥˜ê¸° ê°œì„ 

> ì‚¬ì „ì— í•™ìŠµëœ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ì „ì´ í•™ìŠµì„ ìˆ˜í–‰í•˜ê³  ì´ë¯¸ì§€ ë¶„ë¥˜ê¸°ì˜ ì„±ëŠ¥ í–¥ìƒ
---

### ğŸ“„ ì½”ë“œ 
- Trans_classsification.py

*ì „ì²´ ì½”ë“œ*
```python
import cv2 as cv 
import numpy as np
from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input,decode_predictions

model=ResNet50(weights='imagenet')

img=cv.imread('rabbit.jpg') 
x=np.reshape(cv.resize(img,(224,224)),(1,224,224,3))   
x=preprocess_input(x)

preds=model.predict(x)
top5=decode_predictions(preds,top=5)[0]
print('ì˜ˆì¸¡ ê²°ê³¼:',top5)

for i in range(5):
    cv.putText(img,top5[i][1]+':'+str(top5[i][2]),(10,20+i*20),cv.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),1)

cv.imshow('Recognition result',img)

cv.waitKey()
cv.destroyAllWindows()
```

*í•µì‹¬ ì½”ë“œ* <br>
**ğŸ”· Grayscale ì´ë¯¸ì§€ ë³€í™˜**
```python
gray1 = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)
gray2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)
```
ğŸ”¹ SIFT ì—°ì‚°ì„ ìœ„í•´ Grayscale ì´ë¯¸ì§€ ë³€í™˜
<br><br>
**ğŸ”· SIFT ìˆ˜í–‰**
```python
sift = cv.SIFT_create()
kp1, des1 = sift.detectAndCompute(gray1, None)
kp2, des2 = sift.detectAndCompute(gray2, None)
```
ğŸ”¹ ë‘ ì´ë¯¸ì§€ì—ì„œ íŠ¹ì§•ì ê³¼ desscriptor ì¶”ì¶œ <br>
<br><br>
**ğŸ”· KNN matching ìˆ˜í–‰**
```python
bf = cv.BFMatcher(cv.NORM_L2, crossCheck=False)
matches = bf.knnMatch(des1, des2, k=2)
```
ğŸ”¹ BFMatcher(Brute-Force Matcher)ë¥¼ ì‚¬ìš©í•˜ì—¬ destriptors ê°„ KNN ë§¤ì¹­(k=2)ì„ ìˆ˜í–‰
<br><br>
**ğŸ”· Matching í•„í„°ë§**
```python
good_matches = []
ratio_thresh = 0.7
for m, n in matches:
    if m.distance < ratio_thresh * n.distance:
        good_matches.append(m)
```
ğŸ”¹ ì˜ëª»ëœ ë§¤ì¹­ì„ ì œê±°í•˜ì—¬ ì‹ ë¢°ì„±ì„ ë†’ì„ <br>
<br><br>
**ğŸ”· ì‹¤ì œ ì¢Œí‘œ ì¶”ì¶œ**
```python
src_pts = np.float32([ kp1[m.queryIdx].pt for m in good_matches ]).reshape(-1, 1, 2)
dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good_matches ]).reshape(-1, 1, 2)
```
ğŸ”¹ ë§¤ì¹­ì ì—ì„œ ì‹¤ì œ ì¢Œí‘œë¥¼ ì¶”ì¶œí•˜ì—¬ í˜¸ëª¨ê·¸ë˜í”¼ ê³„ì‚°ì„ ìœ„í•œ ë°ì´í„°ë¡œ ë³€í™˜ <br>
<br><br>
**ğŸ”· í˜¸ëª¨ê·¸ë˜í”¼ ì¶”ì •**
```python
H, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC)
```
ğŸ”¹ RANSAC ê¸°ë°˜ìœ¼ë¡œ í˜¸ëª¨ê·¸ë˜í”¼ í–‰ë ¬ì„ ì¶”ì • <br>
<br><br>
**ğŸ”· ì´ë¯¸ì§€ ì •ë ¬ í›„ ì‹œê°ì  í‘œì‹œ**
```python
h2, w2 = img1.shape[:2]
warped_img = cv.warpPerspective(img2, H, (w2, h2))
img_matches = cv.drawMatches(img1, kp1, warped_img, kp2, good_matches, None,
                             flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)
```
ğŸ”¹ ì¶”ì •ëœ í˜¸ëª¨ê·¸ë˜í”¼ë¥¼ ì´ìš©í•˜ì—¬ img1, img2ì— ì •ë ¬ë˜ë„ë¡ ë³€í˜• <br>
ğŸ”¹ ë§¤ì¹­ ê²°ê³¼ë¥¼ ì‹œê°í™” <br>
![image](https://github.com/user-attachments/assets/89578959-a5bb-40d1-b6b9-1c2402491678)
<br><br>
### :octocat: ì‹¤í–‰ ê²°ê³¼
![ìŠ¤í¬ë¦°ìƒ· 2025-04-08 165415](https://github.com/user-attachments/assets/3e827e65-b681-4262-b8b3-f7b369802f7d)

